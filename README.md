# ENEL 637-Project
# Residue Number Systems for Matrix Multiplication

This project investigates **Residue Number Systems (RNS)** for accelerating large-scale **matrix multiplication (MM)**.  
RNS enables **carry-free modular arithmetic** and parallel execution across residue channels, but it introduces a conversion bottleneck due to **WNS ↔ RNS** encoding/decoding (notably CRT-style reconstruction). The goal of this repository is to provide the **simulation code**, **generated dataset**, and **figures** for the experiment.

---

## What’s in this Repository

- **Code**: Python implementation for comparing WNS vs. RNS matrix multiplication timing (including conversion overhead).
- **Dataset**: Output files generated by the simulation (timing results used for analysis/plots).
- **Figures**: Plots created from the dataset (e.g., speedup vs. matrix size and component-time analysis).



---

## Project Summary

- Uses **k = 4** parallel residue channels
- Example modulus set: **{127, 128, 129, 257}**
- Total RNS time is decomposed into:
  \[
  T_{RNS} = T_{Encode} + T_{Core} + T_{Decode}.
  \]
- The experiment is designed to show when the **parallel RNS core** outweighs the **conversion overhead** as matrix size \(N\) increases.

---

## Setup Instructions

### Step 1: Clone the Repository
```bash
git clone https://github.com/EsmaeilShakeri/ENEL-637-Project.git
cd ENEL-637-Project

### Step 2: Launch and Run the Notebooks
Open the notebooks in the `notebooks/` directory to run each part of the project and reproduce the analysis and figures.

